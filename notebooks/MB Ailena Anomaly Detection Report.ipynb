{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOiAiU2OjIKJHvRqPQn2tEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiedriusDapsys/MB-Ailena-Anomaly-Detection/blob/main/notebooks/MB%20Ailena%20Anomaly%20Detection%20Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJG8aE2Hmz2-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = \"/content/Pardavimai prekiu grupes  2025 01 01 06 30.xlsx\"  # pritaikyk tikslų vardą\n",
        "df = pd.read_excel(DATA_PATH, skiprows=5, header=0)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 1. VALYMAS ----\n",
        "# Užpildom grupių pavadinimus (aukščiau buvę antraščių blokai sukelia NaN)\n",
        "df['Pasirinkta prekė(Grupė)'] = df['Pasirinkta prekė(Grupė)'].ffill()\n",
        "\n",
        "# Paverčiam mėnesį į datetime\n",
        "df['Mėnuo'] = pd.to_datetime(df['Mėnuo'].astype(str), errors='coerce')\n",
        "\n",
        "# Skaitiniai stulpeliai -> float ir užpildom spragas\n",
        "num_cols = ['Kiekis','Pirkimo suma EUR','Pardavimo suma EUR','Pelnas']\n",
        "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce').fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Išmetam aiškius meta-įrašus (jei tokių būtų)\n",
        "mask_meta = (df['Pasirinkta prekė(Grupė)'].astype(str).str.contains('Iš viso|VISO', case=False, na=False)) | (df['Mėnuo'].isna())\n",
        "df = df[~mask_meta].reset_index(drop=True)\n",
        "\n",
        "print(df.dtypes)\n",
        "df.head(3)\n"
      ],
      "metadata": {
        "id": "RAm38kzlu2iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "window_size = 12             # gali keisti\n",
        "X = df[num_cols].values      # 4 bruožai\n",
        "\n",
        "# suformuojam sekas: [N-w+1, w, features]\n",
        "seqs = np.array([X[i:i+window_size] for i in range(len(X)-window_size+1)])\n",
        "print(\"seqs shape:\", seqs.shape)\n",
        "\n",
        "# paprastas 80/20 split\n",
        "split = int(len(seqs)*0.8)\n",
        "train_seqs, test_seqs = seqs[:split], seqs[split:]\n",
        "train_seqs.shape, test_seqs.shape\n"
      ],
      "metadata": {
        "id": "iKwi52GPvLxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "timesteps, n_features = window_size, train_seqs.shape[2]\n",
        "latent_dim = 8  # galima eksperimentuoti\n",
        "\n",
        "inp = layers.Input(shape=(timesteps, n_features))\n",
        "enc = layers.LSTM(latent_dim, activation='tanh')(inp)\n",
        "rep = layers.RepeatVector(timesteps)(enc)\n",
        "dec = layers.LSTM(n_features, activation='tanh', return_sequences=True)(rep)\n",
        "\n",
        "autoencoder = models.Model(inp, dec)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "history = autoencoder.fit(\n",
        "    train_seqs, train_seqs,\n",
        "    epochs=20, batch_size=16, validation_split=0.1, verbose=1\n",
        ")\n",
        "\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend(); plt.title('Autoencoder Loss'); plt.show()\n"
      ],
      "metadata": {
        "id": "8E9rdDOMvONl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rekonstrukcijos klaida (MSE) test rinkinyje\n",
        "recon = autoencoder.predict(test_seqs, verbose=0)\n",
        "mse = np.mean((test_seqs - recon)**2, axis=(1,2))\n",
        "\n",
        "pct = 85  # gali keisti (70–95)\n",
        "thr = np.percentile(mse, pct)\n",
        "flags = mse > thr\n",
        "print(f\"Threshold @{pct}th: {thr:.6f} | anomalies: {flags.sum()}/{len(flags)}\")\n",
        "\n",
        "# žemėlapiavimas atgal į mėnesius ir grupes\n",
        "months = df['Mėnuo'].dt.to_period('M').astype(str)\n",
        "groups = df['Pasirinkta prekė(Grupė)'].astype(str)\n",
        "\n",
        "rows = []\n",
        "for i, is_anom in enumerate(flags):\n",
        "    if not is_anom:\n",
        "        continue\n",
        "    idx = split + i + window_size - 1   # indekso perslinkimas\n",
        "    m = months.iloc[idx]\n",
        "    g = groups.iloc[idx]\n",
        "    # atmetam „Iš viso“ ir kt. triukšmą, jei patektų\n",
        "    if m != 'NaT' and g and ':' not in g and not g.lower().startswith('iš viso'):\n",
        "        rows.append({'Grupė': g, 'Mėnuo': m})\n",
        "\n",
        "import pandas as pd\n",
        "anom_df = pd.DataFrame(rows)\n",
        "anom_df.head()\n"
      ],
      "metadata": {
        "id": "cZ5CbMkEvYJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregation: kiek anomalijų per grupę ir mėnesį\n",
        "pivot_anom = anom_df.pivot_table(index='Grupė', columns='Mėnuo', aggfunc='size', fill_value=0)\n",
        "pivot_anom['Iš viso'] = pivot_anom.sum(axis=1)\n",
        "pivot_anom = pivot_anom.sort_values('Iš viso', ascending=False)\n",
        "\n",
        "display(pivot_anom.head(15))\n",
        "\n",
        "# TOP-10 barh\n",
        "top10 = pivot_anom.head(10)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.barh(top10.index, top10['Iš viso'], color='tomato')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel('Anomalijų skaičius'); plt.title('TOP-10 prekių grupės pagal anomalijas')\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "TYPzPZXWvbpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percentiles = [70, 75, 80, 85, 90, 95]\n",
        "counts = []\n",
        "for p in percentiles:\n",
        "    thr = np.percentile(mse, p)\n",
        "    counts.append((flags := (mse > thr)).sum())\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(percentiles, counts, marker='o')\n",
        "plt.xlabel('Percentilės slenkstis'); plt.ylabel('Anomalijų skaičius')\n",
        "plt.title('Jautrumo analizė'); plt.grid(True, alpha=.3); plt.show()\n"
      ],
      "metadata": {
        "id": "USwCVI1RvfUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paimam top3 pagal 'Iš viso'\n",
        "top3 = list(pivot_anom.head(3).index)\n",
        "\n",
        "fig, axes = plt.subplots(len(top3), 1, figsize=(10, 3*len(top3)), sharex=True)\n",
        "if len(top3) == 1: axes = [axes]\n",
        "\n",
        "for ax, grp in zip(axes, top3):\n",
        "    sub = df[df['Pasirinkta prekė(Grupė)'] == grp].copy()\n",
        "    sub = sub.sort_values('Mėnuo')\n",
        "    ax.plot(sub['Mėnuo'], sub['Pardavimo suma EUR'], label='Pardavimo suma EUR')\n",
        "\n",
        "    # pažymim anomalijų mėnesius šiai grupei\n",
        "    months_anom = anom_df.loc[anom_df['Grupė'] == grp, 'Mėnuo'].unique()\n",
        "    mark = sub['Mėnuo'].dt.to_period('M').astype(str).isin(months_anom)\n",
        "    ax.scatter(sub.loc[mark, 'Mėnuo'], sub.loc[mark, 'Pardavimo suma EUR'], color='red', zorder=3, label='Anomalija')\n",
        "\n",
        "    ax.set_title(grp); ax.legend()\n",
        "\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "metadata": {
        "id": "6AKtwE6fvi9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Flatten: (n_samples, window_size * n_features)\n",
        "train_flat = train_seqs.reshape(train_seqs.shape[0], -1)\n",
        "test_flat  = test_seqs.reshape(test_seqs.shape[0],  -1)\n",
        "\n",
        "train_flat.shape, test_flat.shape\n"
      ],
      "metadata": {
        "id": "HtFozEAuwNk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# 1) Isolation Forest\n",
        "iforest = IsolationForest(\n",
        "    n_estimators=200, contamination='auto', random_state=42\n",
        ")\n",
        "iforest.fit(train_flat)\n",
        "s_if = -iforest.decision_function(test_flat)   # didesnis -> labiau anomalija\n",
        "\n",
        "# 2) One-Class SVM (RBF)\n",
        "ocsvm = OneClassSVM(kernel='rbf', nu=0.05, gamma='scale')\n",
        "ocsvm.fit(train_flat)\n",
        "s_svm = -ocsvm.decision_function(test_flat)    # invertuojam, kad didesnis -> anomalija\n",
        "\n",
        "# 3) Local Outlier Factor (novelty=True kad tiktų .predict ant naujų)\n",
        "lof = LocalOutlierFactor(n_neighbors=35, novelty=True, contamination='auto')\n",
        "lof.fit(train_flat)\n",
        "s_lof = -lof.decision_function(test_flat)      # didesnis -> anomalija\n"
      ],
      "metadata": {
        "id": "WYHc92XZwbIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def minmax(x):\n",
        "    x = np.asarray(x, float)\n",
        "    return (x - x.min()) / (x.max() - x.min() + 1e-12)\n",
        "\n",
        "scores = {\n",
        "    'AE_MSE': minmax(mse),    # iš jūsų AE\n",
        "    'IForest': minmax(s_if),\n",
        "    'OCSVM': minmax(s_svm),\n",
        "    'LOF': minmax(s_lof),\n",
        "}\n",
        "\n",
        "pct = 85  # tas pats kaip AE\n",
        "thresholds = {k: np.percentile(v, pct) for k, v in scores.items()}\n",
        "flags = {k: (v > thresholds[k]) for k, v in scores.items()}\n",
        "\n",
        "# Bendras palyginimo DF (test langų lygiu)\n",
        "comp = pd.DataFrame(scores)\n",
        "comp['month'] = months.iloc[split + window_size - 1 : split + window_size - 1 + len(comp)].values\n",
        "comp['group'] = groups.iloc[split + window_size - 1 : split + window_size - 1 + len(comp)].values\n",
        "for k in flags:\n",
        "    comp[f'{k}_flag'] = flags[k].astype(int)\n",
        "\n",
        "display(comp.head())\n"
      ],
      "metadata": {
        "id": "KDUkrCqtwgBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(a, b):\n",
        "    a = set(np.where(a)[0]); b = set(np.where(b)[0])\n",
        "    return len(a & b) / len(a | b) if len(a | b) > 0 else 0.0\n",
        "\n",
        "base = 'AE_MSE'\n",
        "rows = []\n",
        "for k in scores:\n",
        "    n = int(flags[k].sum())\n",
        "    jac = 1.0 if k == base else jaccard(flags[base], flags[k])\n",
        "    rows.append([k, n, thresholds[k], jac])\n",
        "\n",
        "summary_df = pd.DataFrame(rows, columns=['Model', 'AnomalyCount', 'Threshold', 'Jaccard_vs_AE'])\n",
        "display(summary_df)\n"
      ],
      "metadata": {
        "id": "Qcbd3gU3wi_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(summary_df['Model'], summary_df['AnomalyCount'])\n",
        "plt.title(f'Anomalijų skaičius (@{pct}th)'); plt.ylabel('Count'); plt.show()\n"
      ],
      "metadata": {
        "id": "NdM9ZTYNwliD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anomalies_to_pivot(model_key):\n",
        "    mask = flags[model_key]\n",
        "    rows = []\n",
        "    for i, is_an in enumerate(mask):\n",
        "        if not is_an:\n",
        "            continue\n",
        "        idx = split + i + window_size - 1\n",
        "        m = months.iloc[idx]; g = groups.iloc[idx]\n",
        "        # atmetam bendras sumas / meta eiles\n",
        "        if m != 'NaT' and isinstance(g, str) and ':' not in g and not g.lower().startswith('iš viso'):\n",
        "            rows.append((g, m))\n",
        "    adf = pd.DataFrame(rows, columns=['Grupė','Mėnuo'])\n",
        "    if adf.empty:\n",
        "        return pd.DataFrame()\n",
        "    p = adf.pivot_table(index='Grupė', columns='Mėnuo', aggfunc='size', fill_value=0)\n",
        "    p['Iš viso'] = p.sum(axis=1)\n",
        "    return p.sort_values('Iš viso', ascending=False)\n",
        "\n",
        "pivot_ae = anomalies_to_pivot('AE_MSE').head(10)\n",
        "pivot_if = anomalies_to_pivot('IForest').head(10)\n",
        "pivot_svm = anomalies_to_pivot('OCSVM').head(10)\n",
        "pivot_lof = anomalies_to_pivot('LOF').head(10)\n",
        "\n",
        "print(\"AE – TOP10\"); display(pivot_ae)\n",
        "print(\"IForest – TOP10\"); display(pivot_if)\n",
        "print(\"OCSVM – TOP10\"); display(pivot_svm)\n",
        "print(\"LOF – TOP10\"); display(pivot_lof)\n"
      ],
      "metadata": {
        "id": "pBX6xZhNwqU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === IŠSAUGOJIMAS: grafikai ir lentelės -> /content ===\n",
        "import os\n",
        "os.makedirs(\"/content/report/img\", exist_ok=True)\n",
        "os.makedirs(\"/content/report/tables\", exist_ok=True)\n",
        "\n",
        "# 1) Modelių anomalijų skaičiaus grafikas\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(summary_df['Model'], summary_df['AnomalyCount'])\n",
        "plt.title(f'Anomalijų skaičius (@{pct}th)'); plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/report/img/anomaly_count_by_model.png\", dpi=160, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 2) Modelių palyginimo lentelė (CSV ir Markdown)\n",
        "summary_df.to_csv(\"/content/report/tables/model_summary.csv\", index=False)\n",
        "with open(\"/content/report/tables/model_summary.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(summary_df.to_markdown(index=False))\n",
        "\n",
        "# 3) TOP-10 pivot lentelės pagal modelį (CSV ir Markdown)\n",
        "def save_pivot(name, pivot):\n",
        "    if pivot is None or pivot.empty:\n",
        "        return\n",
        "    pivot10 = pivot.head(10)\n",
        "    pivot10.to_csv(f\"/content/report/tables/{name}_top10.csv\")\n",
        "    with open(f\"/content/report/tables/{name}_top10.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(pivot10.to_markdown())\n",
        "\n",
        "save_pivot(\"ae\",    pivot_ae)\n",
        "save_pivot(\"ifor\",  pivot_if)\n",
        "save_pivot(\"ocsvm\", pivot_svm)\n",
        "save_pivot(\"lof\",   pivot_lof)\n",
        "\n",
        "print(\"✓ Išsaugota į /content/report/img ir /content/report/tables\")\n"
      ],
      "metadata": {
        "id": "ZJdvVRN3ws50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/report_artifacts.zip /content/report\n",
        "from google.colab import files\n",
        "files.download('/content/report_artifacts.zip')\n"
      ],
      "metadata": {
        "id": "ZxKyUf_d0owk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "BASE = Path('/content/report/tables')  # jei reikia, pataisyk kelią\n",
        "\n",
        "# 1) Įkeliam TOP lenteles (jei .md – naudok read_table; jei .csv – read_csv)\n",
        "def read_any(p):\n",
        "    p = Path(p)\n",
        "    if p.suffix == '.csv':\n",
        "        return pd.read_csv(p)\n",
        "    elif p.suffix == '.md':\n",
        "        # md konvertuojam į csv-like, praleidžiam header separatorius\n",
        "        df = pd.read_table(p, sep='|', engine='python', skiprows=1)\n",
        "        # numest nereikalingas kolonas (md turi daug tuščių stulpelių)\n",
        "        df = df.dropna(axis=1, how='all')\n",
        "        # išvalom whitespace ir header eilutę, jei yra\n",
        "        df.columns = [c.strip() for c in df.columns]\n",
        "        # kartais pirmas/galinis stulpelis būna tuščias\n",
        "        keep = [c for c in df.columns if c not in ['', 'Unnamed: 0']]\n",
        "        df = df[keep]\n",
        "        return df\n",
        "    else:\n",
        "        raise ValueError(f'Nežinomas formatas: {p}')\n",
        "\n",
        "ae   = read_any(BASE/'ae_top10.csv')\n",
        "ifor = read_any(BASE/'ifor_top10.csv')\n",
        "ocsvm= read_any(BASE/'ocsvm_top10.csv')\n",
        "lof  = read_any(BASE/'lof_top10.csv')\n",
        "\n",
        "# 2) Sutvarkom pavadinimus: bandysim atspėti laukus\n",
        "def normalize_cols(df):\n",
        "    cols = {c.lower(): c for c in df.columns}\n",
        "    # bandome atspėti stulpelių pavadinimus\n",
        "    group_col = next((cols[k] for k in cols if 'grup' in k or 'prek' in k), None)\n",
        "    month_col = next((cols[k] for k in cols if 'mėnuo' in k or 'menuo' in k or 'men' in k), None)\n",
        "    score_col = next((cols[k] for k in cols if 'score' in k or 'mse' in k or 'klaida' in k), None)\n",
        "\n",
        "    # paliekam tik naudingus\n",
        "    keep = [c for c in [group_col, month_col, score_col] if c is not None]\n",
        "    out = df[keep].copy()\n",
        "    # pervadinam\n",
        "    ren = {}\n",
        "    if group_col: ren[group_col] = 'Group'\n",
        "    if month_col: ren[month_col] = 'Month'\n",
        "    if score_col: ren[score_col] = 'Score'\n",
        "    out = out.rename(columns=ren)\n",
        "    return out\n",
        "\n",
        "ae   = normalize_cols(ae)\n",
        "ifor = normalize_cols(ifor)\n",
        "ocsvm= normalize_cols(ocsvm)\n",
        "lof  = normalize_cols(lof)\n",
        "\n",
        "# 3) „Raktas“ – grupė + mėnuo (kas apibrėžia vieną anomalijos langą)\n",
        "for df in [ae, ifor, ocsvm, lof]:\n",
        "    if 'Month' in df.columns:\n",
        "        df['Month'] = pd.to_datetime(df['Month'], errors='coerce')\n",
        "\n",
        "def key_df(df, model_name):\n",
        "    if 'Group' in df.columns and 'Month' in df.columns:\n",
        "        k = df[['Group','Month']].dropna().copy()\n",
        "        k['model'] = model_name\n",
        "        return k\n",
        "    elif 'Group' in df.columns:\n",
        "        k = df[['Group']].dropna().copy()\n",
        "        k['Month'] = pd.NaT\n",
        "        k['model'] = model_name\n",
        "        return k\n",
        "    else:\n",
        "        return pd.DataFrame(columns=['Group','Month','model'])\n",
        "\n",
        "K = pd.concat([\n",
        "    key_df(ae, 'AE_MSE'),\n",
        "    key_df(ifor, 'IForest'),\n",
        "    key_df(ocsvm, 'OCSVM'),\n",
        "    key_df(lof, 'LOF')\n",
        "], ignore_index=True).drop_duplicates()\n",
        "\n",
        "# 4) Skaičiai: kiek per modelį\n",
        "per_model_counts = K.groupby('model').size().sort_index()\n",
        "print('Anomalijų per modelį:\\n', per_model_counts, '\\n')\n",
        "\n",
        "# 5) Unikalus anomalijų langų skaičius (sąjunga tarp modelių)\n",
        "unique_windows = K[['Group','Month']].drop_duplicates().shape[0]\n",
        "print('Bendras unikalių anomalijų (grupė+mėnuo) skaičius:', unique_windows, '\\n')\n",
        "\n",
        "# 6) Kurios grupės dažniausiai pasikartoja (kartu tarp modelių)\n",
        "grp_freq = K.groupby('Group').size().sort_values(ascending=False)\n",
        "print('Grupių dažniai (kartų skaičius tarp modelių):\\n', grp_freq.head(10), '\\n')\n",
        "\n",
        "# 7) Persidengimai: kiek langų sutampa tarp modelių (Jaccard rodyklė tarp porų)\n",
        "def jaccard(A, B):\n",
        "    inter = len(A & B)\n",
        "    union = len(A | B)\n",
        "    return inter/union if union>0 else 0.0\n",
        "\n",
        "def keyset(df):\n",
        "    return set(zip(df['Group'], df['Month']))\n",
        "\n",
        "S = {\n",
        "    'AE_MSE': keyset(key_df(ae,'AE_MSE')),\n",
        "    'IForest': keyset(key_df(ifor,'IForest')),\n",
        "    'OCSVM' : keyset(key_df(ocsvm,'OCSVM')),\n",
        "    'LOF'   : keyset(key_df(lof,'LOF')),\n",
        "}\n",
        "\n",
        "pairs = [('AE_MSE','IForest'), ('AE_MSE','OCSVM'), ('AE_MSE','LOF'),\n",
        "         ('IForest','OCSVM'), ('IForest','LOF'), ('OCSVM','LOF')]\n",
        "\n",
        "print('Poriniai persidengimai (Jaccard):')\n",
        "for a,b in pairs:\n",
        "    print(f'  {a} vs {b}: {jaccard(S[a], S[b]):.2f}')\n"
      ],
      "metadata": {
        "id": "GXg7M6eZ9Rwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Jautrumo kreivė: automatinis Excel paėmimas + braižymas =================\n",
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# (1) Jei žinai tikslų kelią – įrašyk čia ir atkomentuok:\n",
        "# DATA_PATH = \"/content/Pardavimai prekiu grupes  2025 01 01 06 30.xlsx\"\n",
        "\n",
        "def ensure_excel_path():\n",
        "    \"\"\"Grąžina Excel failo kelią: iš DATA_PATH, /content paieškos arba paprašant įkelti.\"\"\"\n",
        "    # a) jei DATA_PATH jau yra apibrėžtas ir egzistuoja\n",
        "    if 'DATA_PATH' in globals():\n",
        "        p = Path(DATA_PATH)\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "\n",
        "    # b) ieškome /content *.xlsx\n",
        "    candidates = glob.glob(\"/content/*.xlsx\")\n",
        "    if candidates:\n",
        "        # jei yra keli, pirmenybė su 'Pardav' pavadinime, kitaip pirmas\n",
        "        for p in candidates:\n",
        "            if \"Pardav\" in os.path.basename(p):\n",
        "                return p\n",
        "        return candidates[0]\n",
        "\n",
        "    # c) paprašome įkelti (Colab failų įkėlimo langas)\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        uploaded = files.upload()  # vartotojas pasirenka .xlsx\n",
        "        if uploaded:\n",
        "            # imame pirmą įkeltą\n",
        "            fname = list(uploaded.keys())[0]\n",
        "            return f\"/content/{fname}\"\n",
        "    except Exception as e:\n",
        "        print(\"Nepavyko paleisti files.upload(). Klaida:\", e)\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Nerasta .xlsx. Įkelkite Excel į Colab (kairėje Files skydelyje Upload) \"\n",
        "        \"arba nurodykite DATA_PATH = '/content/tavo_failas.xlsx'.\"\n",
        "    )\n",
        "\n",
        "# 1) Užtikrinam kelią ir įkeliame duomenis į df\n",
        "excel_path = ensure_excel_path()\n",
        "print(f\"Naudojamas Excel: {excel_path}\")\n",
        "df = pd.read_excel(excel_path, skiprows=5, header=0)\n",
        "\n",
        "# 2) Pasirenkame skaitinius stulpelius (kiekis/pirkimo/pardavimo/pelnas) – jautrumui užteks kelių\n",
        "def pick_col(df, candidates):\n",
        "    low = {c.lower(): c for c in df.columns}\n",
        "    for cand in candidates:\n",
        "        for k, orig in low.items():\n",
        "            if cand in k:\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "col_kiekis = pick_col(df, ['kiekis'])\n",
        "col_buy    = pick_col(df, ['pirkimo suma', 'pirkimo'])\n",
        "col_sell   = pick_col(df, ['pardavimo suma', 'pardavimo'])\n",
        "col_profit = pick_col(df, ['pelnas'])\n",
        "\n",
        "use_cols = [c for c in [col_kiekis, col_buy, col_sell, col_profit] if c is not None]\n",
        "if len(use_cols) < 2:\n",
        "    raise ValueError(f\"Neradau pakankamai skaitinių stulpelių. Rasta: {use_cols}\")\n",
        "\n",
        "X = df[use_cols].apply(pd.to_numeric, errors='coerce')\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "# 3) Isolation Forest balas (kuo didesnis, tuo 'keistesnis')\n",
        "iso = IsolationForest(n_estimators=300, contamination=0.05, random_state=42)\n",
        "iso.fit(X)\n",
        "scores = -iso.score_samples(X)\n",
        "\n",
        "# 4) Jautrumo kreivė – kiek anomalijų, jei slenkstis p-tasis procentilis\n",
        "pct_list = [70, 75, 80, 85, 90, 95]\n",
        "rows = []\n",
        "for p in pct_list:\n",
        "    thr = np.percentile(scores, p)\n",
        "    n_anom = int((scores > thr).sum())\n",
        "    rows.append({'pct': p, 'n': n_anom})\n",
        "sensitivity_df = pd.DataFrame(rows)\n",
        "print(\"sensitivity_df:\\n\", sensitivity_df)\n",
        "\n",
        "# 5) Išsaugome grafiką\n",
        "out_dir = Path('/content/report/img')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "plt.figure()\n",
        "ax = sensitivity_df.set_index('pct')['n'].plot(marker='o')\n",
        "ax.set_xlabel('Percentile threshold')\n",
        "ax.set_ylabel('Number of anomalies')\n",
        "ax.set_title('Jautrumo kreivė (IsolationForest)')\n",
        "plt.tight_layout()\n",
        "out_path = out_dir / 'sensitivity.png'\n",
        "plt.savefig(out_path, dpi=150)\n",
        "plt.close()\n",
        "\n",
        "print(f\"✓ Grafikas išsaugotas: {out_path}\")\n"
      ],
      "metadata": {
        "id": "fGZLV0_XQGst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}